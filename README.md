# Machine-Learning-Numpy

Code Machine learning models without any frameworks, Numpy only.

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Python-logo-notext.svg/2000px-Python-logo-notext.svg.png" align="right" width="20%">

## Table of contents
* [Neural Network](https://github.com/huseinzol05/Machine-Learning-Numpy#neural-network)
* [Clustering](https://github.com/huseinzol05/Machine-Learning-Numpy#clustering)
* [Decomposition](https://github.com/huseinzol05/Machine-Learning-Numpy#decomposition)
* [Probabilistic](https://github.com/huseinzol05/Machine-Learning-Numpy#probabilistic)
* [Regression](https://github.com/huseinzol05/Machine-Learning-Numpy#regression)
* [Trees based](https://github.com/huseinzol05/Machine-Learning-Numpy#trees-based)
* [Timeseries](https://github.com/huseinzol05/Machine-Learning-Numpy#timeseries)
* [Signal processing](https://github.com/huseinzol05/Machine-Learning-Numpy#signal-processing)

### Neural Network

1. **Deep Feed-forward**
  * gradient descent
  * momentum
  * nesterov
  * rmsprop
  * adagrad
  * adam

2. **Vanilla recurrent**
  * gradient descent
  * momentum
  * nesterov
  * rmsprop
  * adagrad
  * adam

3. **Long-short-term-memory recurrent**
  * gradient descent
  * momentum
  * nesterov
  * rmsprop
  * adagrad
  * adam

4. **gated-recurrent-unit recurrent**
  * gradient descent
  * momentum
  * nesterov
  * rmsprop
  * adagrad
  * adam

5. **Convolutional**
  * atrous 1D
  * atrous 2D
  * average pooling 1D
  * average pooling 2D
  * convolution 1D
  * convolution 2D
  * max pooling 1D
  * max pooling 2D

6. batch-normalization
7. Dropout
8. Regularization
9. Neuro-evolution
10. Evolution-strategy

### Clustering

1. DBScan
2. K-Mean
3. K-Nearest Neighbors

### Decomposition

1. Latent Dirichlet Allocation
2. Latent Semantic Analysis
3. Linear Decomposition Analysis
4. Non-negative Matrix Feature
5. Principal Component Analysis
6. TSNE

### Probabilistic

1. Gaussian TF-IDF
2. Multinomial TF-IDF
3. Hidden Markov

### Regression

1. Linear
2. Polynomial
3. Lasso
4. Ridge
5. Sigmoid logistic

### Trees based

1. Decision Tree
2. Random Forest
3. Adaptive Boosting
4. Bagging
5. Gradient Boosting

### Timeseries

1. Moving Average
2. Linear Weight Moving Average
3. John-Ehlers
4. Noise Removal-Get
5. Anchor Smoothing
6. Detect Outliers
7. ARIMA

### Signal processing

1. Convolutional 1D
2. Convolutional 2D
3. Pass-Filters

## Discussions

Some of results are not good because of softmax and cross entropy functions I code.

If found any error on my chain-rules, feel free to branch.
