{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "import re\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearstring(string):\n",
    "    string = re.sub('[^A-Za-z0-9 ]+', '', string)\n",
    "    string = string.split(' ')\n",
    "    string = filter(None, string)\n",
    "    string = [y.strip() for y in string]\n",
    "    string = ' '.join(string)\n",
    "    return string\n",
    "\n",
    "def separate_dataset(trainset):\n",
    "    datastring = []\n",
    "    datatarget = []\n",
    "    for i in range(len(trainset.data)):\n",
    "        data_ = trainset.data[i].split('\\n')\n",
    "        data_ = list(filter(None, data_))\n",
    "        for n in range(len(data_)):\n",
    "            data_[n] = clearstring(data_[n])\n",
    "        datastring += data_\n",
    "        for n in range(len(data_)):\n",
    "            datatarget.append(trainset.target[i])\n",
    "    return datastring, datatarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kerajaan', 'pembangkang']\n",
      "201\n",
      "201\n"
     ]
    }
   ],
   "source": [
    "trainset = sklearn.datasets.load_files(container_path = 'local', encoding = 'UTF-8')\n",
    "trainset.data, trainset.target = separate_dataset(trainset)\n",
    "print (trainset.target_names)\n",
    "print (len(trainset.data))\n",
    "print (len(trainset.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1737"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = list(set(' '.join(trainset.data).split()))\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate IDF\n",
    "idf = {}\n",
    "for i in vocabulary:\n",
    "    idf[i] = 0\n",
    "    for k in trainset.data:\n",
    "        if i in k.split():\n",
    "            idf[i] += 1\n",
    "    idf[i] = np.log(idf[i] / len(trainset.data))\n",
    "\n",
    "# calculate TF\n",
    "X = np.zeros((len(trainset.data),len(vocabulary)))\n",
    "for no, i in enumerate(trainset.data):\n",
    "    for text in i.split():\n",
    "        X[no, vocabulary.index(text)] += 1\n",
    "    for text in i.split():\n",
    "        # calculate TF * IDF\n",
    "        X[no, vocabulary.index(text)] = X[no, vocabulary.index(text)] * idf[text]\n",
    "        \n",
    "X = np.abs(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(X, trainset.target, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNB:\n",
    "    def __init__(self, epsilon):\n",
    "        self.EPSILON = epsilon\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        count_sample = X.shape[0]\n",
    "        separated = [[x for x, t in zip(X, y) if t == c] for c in np.unique(y)]\n",
    "        self.class_log_prior_ = [np.log((len(i) / count_sample)+self.EPSILON) for i in separated]\n",
    "        count = np.array([np.array(i).sum(axis=0) for i in separated])\n",
    "        self.feature_log_prob_ = np.log((count / count.sum(axis=1)[np.newaxis].T)+self.EPSILON)\n",
    "\n",
    "    def predict_log_proba(self, X):\n",
    "        log_proba = [(self.feature_log_prob_ * x).sum(axis=1) + self.class_log_prior_ for x in X]\n",
    "        return [1-(i/np.sum(i)) for i in log_proba]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_log_proba(X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomial_bayes = MultinomialNB(1e-8)\n",
    "multinomial_bayes.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_Y == multinomial_bayes.predict(train_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9024390243902439"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_Y == multinomial_bayes.predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.4160699, 0.5839301]),\n",
       " array([0.55938444, 0.44061556]),\n",
       " array([0.59284875, 0.40715125]),\n",
       " array([0.62516137, 0.37483863]),\n",
       " array([0.44937446, 0.55062554]),\n",
       " array([0.45295124, 0.54704876]),\n",
       " array([0.44677705, 0.55322295]),\n",
       " array([0.53576261, 0.46423739]),\n",
       " array([0.47820352, 0.52179648]),\n",
       " array([0.46795305, 0.53204695]),\n",
       " array([0.52081375, 0.47918625]),\n",
       " array([0.42479686, 0.57520314]),\n",
       " array([0.48283977, 0.51716023]),\n",
       " array([0.41845241, 0.58154759]),\n",
       " array([0.50002556, 0.49997444]),\n",
       " array([0.55858497, 0.44141503]),\n",
       " array([0.55340458, 0.44659542]),\n",
       " array([0.42416387, 0.57583613]),\n",
       " array([0.55213442, 0.44786558]),\n",
       " array([0.53164622, 0.46835378]),\n",
       " array([0.39331215, 0.60668785]),\n",
       " array([0.41795026, 0.58204974]),\n",
       " array([0.60649046, 0.39350954]),\n",
       " array([0.46393913, 0.53606087]),\n",
       " array([0.43016626, 0.56983374]),\n",
       " array([0.59933077, 0.40066923]),\n",
       " array([0.4685191, 0.5314809]),\n",
       " array([0.64641473, 0.35358527]),\n",
       " array([0.51236647, 0.48763353]),\n",
       " array([0.55986553, 0.44013447]),\n",
       " array([0.57764321, 0.42235679]),\n",
       " array([0.62207619, 0.37792381]),\n",
       " array([0.5164248, 0.4835752]),\n",
       " array([0.50977479, 0.49022521]),\n",
       " array([0.62896208, 0.37103792]),\n",
       " array([0.42999558, 0.57000442]),\n",
       " array([0.56070499, 0.43929501]),\n",
       " array([0.42537593, 0.57462407]),\n",
       " array([0.61558156, 0.38441844]),\n",
       " array([0.37974083, 0.62025917]),\n",
       " array([0.41550321, 0.58449679])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial_bayes.predict_log_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
