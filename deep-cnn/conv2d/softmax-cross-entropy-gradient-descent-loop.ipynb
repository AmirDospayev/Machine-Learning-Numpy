{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import scipy.io.wavfile\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "def pad_audio(samples, L=16000):\n",
    "    if len(samples) >= L: return samples\n",
    "    else: return np.pad(samples, pad_width=(L - len(samples), 0), mode='constant', constant_values=(0, 0))\n",
    "\n",
    "def chop_audio(samples, L=16000, num=20):\n",
    "    for i in range(num):\n",
    "        beg = np.random.randint(0, len(samples) - L)\n",
    "        yield samples[beg: beg + L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seven', 'one', 'five', 'nine', 'down', 'four', 'eight']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_location = os.listdir('/home/husein/Desktop/convolutional-neural-network/audio')\n",
    "audio_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "new_sample_rate = 8000\n",
    "for i in audio_location:\n",
    "    audios = os.listdir('/home/husein/Desktop/convolutional-neural-network/audio/%s'%(i))\n",
    "    for k in audios:\n",
    "        sample_rate, samples = scipy.io.wavfile.read(os.path.join('/home/husein/Desktop/convolutional-neural-network/audio', i, k))\n",
    "        samples = pad_audio(samples)\n",
    "        if len(samples) > 16000:\n",
    "            n_samples = chop_audio(samples)\n",
    "        else: \n",
    "            n_samples = [samples]\n",
    "        for samples in n_samples:\n",
    "            resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n",
    "            _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n",
    "            Y.append(i)\n",
    "            X.append(np.expand_dims(scipy.misc.imresize(specgram,[45, 40]),axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.unique(Y)\n",
    "Y = LabelEncoder().fit_transform(Y)\n",
    "c = list(zip(X, Y))\n",
    "random.shuffle(c)\n",
    "X, Y = zip(*c)\n",
    "X, Y = np.array(X), np.array(Y)\n",
    "onehot = np.zeros((X.shape[0],labels.shape[0]))\n",
    "onehot[np.arange(Y.shape[0]), Y] = 1.0\n",
    "filter_size = 3\n",
    "stride = 2\n",
    "epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(Y_hat, Y, epsilon=1e-12):\n",
    "    Y_hat = np.clip(Y_hat, epsilon, 1. - epsilon)\n",
    "    N = Y_hat.shape[0]\n",
    "    return -np.sum(np.sum(Y * np.log(Y_hat+1e-9))) / N\n",
    "\n",
    "def softmax(x):\n",
    "    exp_scores = np.exp(x - np.max(x))\n",
    "    return exp_scores / (np.sum(exp_scores, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "def relu_forward(X):\n",
    "    out = np.maximum(X, 0)\n",
    "    cached = X\n",
    "    return out, cached\n",
    "\n",
    "def relu_backward(X, cached):\n",
    "    X[cached <= 0] = 0\n",
    "    return X\n",
    "\n",
    "def padding(x, filter_size, pad='SAME'):\n",
    "    if pad == 'SAME':\n",
    "        pad_h_min = int(np.floor((filter_size - 1)/2))\n",
    "        pad_h_max = int(np.ceil((filter_size - 1)/2))\n",
    "        pad_w_min = int(np.floor((filter_size - 1)/2))\n",
    "        pad_w_max = int(np.ceil((filter_size - 1)/2))\n",
    "        pad_h, pad_w = (pad_h_min, pad_h_max), (pad_w_min, pad_w_max)\n",
    "        return np.pad(x, ((0, 0), pad_h, pad_w, (0, 0)), mode='constant')\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def get_shape(x):\n",
    "    output_height = int((x.shape[1] - filter_size) / stride + 1)\n",
    "    output_width = int((x.shape[2] - filter_size) / stride + 1)\n",
    "    return int(output_height), int(output_width)\n",
    "\n",
    "def conv(x, w, out):\n",
    "    for k in range(x.shape[0]):\n",
    "        for z in range(w.shape[3]):\n",
    "            h_range = int((x.shape[1] - filter_size) / stride + 1)\n",
    "            for _h in range(h_range):\n",
    "                w_range = int((x.shape[2] - filter_size) / stride + 1)\n",
    "                for _w in range(w_range):\n",
    "                    out[k, _h, _w, z] = np.sum(x[k, \n",
    "                                                 _h * stride:_h * stride + filter_size, \n",
    "                                                 _w * stride:_w * stride + filter_size, :] * w[:, :, :, z])\n",
    "    return out\n",
    "\n",
    "def deconv_w(x, w, dv):\n",
    "    for k in range(x.shape[0]):\n",
    "        for z in range(w.shape[3]):\n",
    "            h_range = int((x.shape[1] - filter_size) / stride + 1)\n",
    "            for _h in range(h_range):\n",
    "                w_range = int((x.shape[2] - filter_size) / stride + 1)\n",
    "                for _w in range(w_range):\n",
    "                    w[:, :, :, z] = np.sum(x[k,\n",
    "                                             _h * stride:_h * stride + filter_size, \n",
    "                                             _w * stride:_w * stride + filter_size, :] * dv[k,\n",
    "                                             _h * stride:_h * stride + filter_size, \n",
    "                                             _w * stride:_w * stride + filter_size, :])\n",
    "    return w\n",
    "\n",
    "def deconv_x(x, w, dv):\n",
    "    for k in range(x.shape[0]):\n",
    "        for z in range(x.shape[3]):\n",
    "            h_range = int((dv.shape[1] - filter_size) / stride + 1)\n",
    "            for _h in range(h_range):\n",
    "                w_range = int((dv.shape[2] - filter_size) / stride + 1)\n",
    "                for _w in range(w_range):\n",
    "                    x[k, _h, _w, z] = np.sum(dv[k, \n",
    "                                                 _h * stride:_h * stride + filter_size, \n",
    "                                                 _w * stride:_w * stride + filter_size, :] * w[:, :, z, :])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_dimension = X[0].shape[2]\n",
    "kernel_1 = np.random.randn(filter_size, filter_size, starting_dimension, 16) / np.sqrt(starting_dimension)\n",
    "kernel_2 = np.random.randn(filter_size, filter_size, 16, 32) / np.sqrt(16)\n",
    "kernel_3 = np.random.randn(filter_size, filter_size, 32, 64) / np.sqrt(32)\n",
    "h_pulled = int(np.ceil(X[0].shape[0] / 2**3))\n",
    "w_pulled = int(np.ceil(X[0].shape[1] / 2**3))\n",
    "w_1 = np.random.randn(h_pulled * w_pulled * 64, 128) / np.sqrt(h_pulled * w_pulled * 64)\n",
    "w_2 = np.random.randn(128, labels.shape[0]) / np.sqrt(128)\n",
    "\n",
    "LEARNING_RATE = 1e-9\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, cost 20.426235, accuracy 0.185714\n",
      "epoch 1, cost 1.945910, accuracy 0.142857\n",
      "epoch 2, cost 1.945910, accuracy 0.142857\n",
      "epoch 3, cost 1.945910, accuracy 0.142857\n",
      "epoch 4, cost 1.945910, accuracy 0.142857\n",
      "epoch 5, cost 1.945910, accuracy 0.142857\n",
      "epoch 6, cost 1.945910, accuracy 0.142857\n",
      "epoch 7, cost 1.945910, accuracy 0.142857\n",
      "epoch 8, cost 1.945910, accuracy 0.142857\n",
      "epoch 9, cost 1.945910, accuracy 0.142857\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCH):\n",
    "    padded_x = padding(X, filter_size)\n",
    "    h, w = get_shape(padded_x)\n",
    "    out_conv1 = np.zeros((X.shape[0], h, w, kernel_1.shape[3]))\n",
    "    out_conv1 = conv(padded_x, kernel_1, out_conv1)\n",
    "    z1, relu_cached1 = relu_forward(out_conv1)\n",
    "    padded_z1 = padding(z1, filter_size)\n",
    "    h, w = get_shape(padded_z1)\n",
    "    out_conv2 = np.zeros((X.shape[0], h, w, kernel_2.shape[3]))\n",
    "    out_conv2 = conv(padded_z1, kernel_2, out_conv2)\n",
    "    z2, relu_cached2 = relu_forward(out_conv2)\n",
    "    padded_z2 = padding(z2, filter_size)\n",
    "    h, w = get_shape(padded_z2)\n",
    "    out_conv3 = np.zeros((X.shape[0], h, w, kernel_3.shape[3]))\n",
    "    out_conv3 = conv(padded_z2, kernel_3, out_conv3)\n",
    "    z3, relu_cached3 = relu_forward(out_conv3)\n",
    "    z3_reshape = z3.reshape((-1, h_pulled * w_pulled * 64))\n",
    "    fully1 = np.dot(z3_reshape, w_1)\n",
    "    z4, relu_cached4 = relu_forward(fully1)\n",
    "    logits = np.dot(z4, w_2)\n",
    "    probs = softmax(logits)\n",
    "    accuracy = np.mean(np.argmax(logits,axis=1) == Y)\n",
    "    loss = cross_entropy(probs, onehot)\n",
    "    delta = probs\n",
    "    delta[range(Y.shape[0]), Y] -= 1\n",
    "    dw_2 = np.dot(z4.T, delta)\n",
    "    dz4 = np.dot(delta,w_2.T)\n",
    "    dfully1 = relu_backward(fully1, relu_cached4) * dz4\n",
    "    dw_1 = np.dot(z3_reshape.T, dfully1)\n",
    "    dz3_reshape = np.dot(dfully1,w_1.T)\n",
    "    dz3 = dz3_reshape.reshape((-1, h_pulled, w_pulled, 64))\n",
    "    dout_conv3 = relu_backward(out_conv3, relu_cached3) * dz3\n",
    "    dkernel_3 = np.zeros(kernel_3.shape)\n",
    "    dpadded_z2 = np.zeros(padded_z2.shape)\n",
    "    dkernel_3 = deconv_w(out_conv3, dkernel_3, dout_conv3)\n",
    "    dpadded_z2 = deconv_x(dpadded_z2, kernel_3, dout_conv3)\n",
    "    dout_conv2 = relu_backward(out_conv2, relu_cached2) * dpadded_z2[:,:out_conv2.shape[1],\n",
    "                                                             :out_conv2.shape[2],:]\n",
    "    dkernel_2 = np.zeros(kernel_2.shape)\n",
    "    dpadded_z1 = np.zeros(padded_z1.shape)\n",
    "    dkernel_1 = deconv_w(out_conv2, dkernel_2, dout_conv2)\n",
    "    dpadded_z1 = deconv_x(dpadded_z1, kernel_2, dout_conv2)\n",
    "    dout_conv1 = relu_backward(out_conv1, relu_cached1) * dpadded_z1[:,:out_conv1.shape[1],\n",
    "                                                             :out_conv1.shape[2],:]\n",
    "    dkernel_1 = np.zeros(kernel_1.shape)\n",
    "    dkernel_1 = deconv_w(out_conv1, dkernel_1, dout_conv1)\n",
    "    kernel_1 += -LEARNING_RATE * dkernel_1\n",
    "    kernel_2 += -LEARNING_RATE * dkernel_2\n",
    "    kernel_3 += -LEARNING_RATE * dkernel_3\n",
    "    w_2 += -LEARNING_RATE * dw_2\n",
    "    w_1 += -LEARNING_RATE * dw_1\n",
    "    print('epoch %d, cost %f, accuracy %f'%(i, loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
