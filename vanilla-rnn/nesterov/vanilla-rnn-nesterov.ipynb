{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import time\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(file, lower = False):\n",
    "    with open(file, 'r') as fopen:\n",
    "        data = fopen.read()\n",
    "    if lower:\n",
    "        data = data.lower()\n",
    "    vocab = list(set(data))\n",
    "    return data, vocab\n",
    "\n",
    "def embed_to_onehot(data, vocab):\n",
    "    onehot = np.zeros((len(data), len(vocab)), dtype = np.float32)\n",
    "    for i in range(len(data)):\n",
    "        onehot[i, vocab.index(data[i])] = 1.0\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, text_vocab = get_vocab('consumer.h', lower = False)\n",
    "onehot = embed_to_onehot(text, text_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "batch_size = 64\n",
    "sequence_length = 12\n",
    "epoch = 1000\n",
    "num_layers = 2\n",
    "size_layer = 128\n",
    "possible_batch_id = range(len(text) - sequence_length - 1)\n",
    "dimension = onehot.shape[1]\n",
    "momentum = 0.9\n",
    "\n",
    "U = np.random.randn(size_layer, dimension) / np.sqrt(size_layer)\n",
    "U_velocity = np.zeros(U.shape)\n",
    "W = np.random.randn(size_layer, size_layer) / np.sqrt(size_layer)\n",
    "W_velocity = np.zeros(W.shape)\n",
    "V = np.random.randn(dimension, size_layer) / np.sqrt(dimension)\n",
    "V_velocity = np.zeros(V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x, grad=False):\n",
    "    if grad:\n",
    "        output = np.tanh(x)\n",
    "        return (1.0 - np.square(output))\n",
    "    else:\n",
    "        return np.tanh(x)\n",
    "    \n",
    "def softmax(x):\n",
    "    exp_scores = np.exp(x - np.max(x))\n",
    "    return exp_scores / (np.sum(exp_scores, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "def derivative_softmax_cross_entropy(x, y):\n",
    "    delta = softmax(x)\n",
    "    delta[range(X.shape[0]), y] -= 1\n",
    "    return delta\n",
    "\n",
    "def forward_multiply_gate(w, x):\n",
    "    return np.dot(w, x)\n",
    "\n",
    "def backward_multiply_gate(w, x, dz):\n",
    "    dW = np.dot(dz.T, x)\n",
    "    dx = np.dot(w.T, dz.T)\n",
    "    return dW, dx\n",
    "\n",
    "def forward_add_gate(x1, x2):\n",
    "    return x1 + x2\n",
    "\n",
    "def backward_add_gate(x1, x2, dz):\n",
    "    dx1 = dz * np.ones_like(x1)\n",
    "    dx2 = dz * np.ones_like(x2)\n",
    "    return dx1, dx2\n",
    "\n",
    "def cross_entropy(Y_hat, Y, epsilon=1e-12):\n",
    "    Y_hat = np.clip(Y_hat, epsilon, 1. - epsilon)\n",
    "    N = Y_hat.shape[0]\n",
    "    return -np.sum(np.sum(Y * np.log(Y_hat+1e-9))) / N\n",
    "\n",
    "def forward_recurrent(x, prev_state, U, W, V):\n",
    "    mul_u = forward_multiply_gate(x, U.T)\n",
    "    mul_w = forward_multiply_gate(prev_state, W.T)\n",
    "    add_previous_now = forward_add_gate(mul_u, mul_w)\n",
    "    current_state = tanh(add_previous_now)\n",
    "    mul_v = forward_multiply_gate(current_state, V.T)\n",
    "    return (mul_u, mul_w, add_previous_now, current_state, mul_v)\n",
    "\n",
    "def backward_recurrent(x, prev_state, U, W, V, d_mul_v, saved_graph):\n",
    "    mul_u, mul_w, add_previous_now, current_state, mul_v = saved_graph\n",
    "    dV, dcurrent_state = backward_multiply_gate(V, current_state, d_mul_v)\n",
    "    dadd_previous_now = tanh(add_previous_now, True) * dcurrent_state.T\n",
    "    dmul_w, dmul_u = backward_add_gate(mul_w, mul_u, dadd_previous_now)\n",
    "    dW, dprev_state = backward_multiply_gate(W, prev_state, dmul_w)\n",
    "    dU, dx = backward_multiply_gate(U, x, dmul_u)\n",
    "    return (dprev_state, dU, dW, dV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, loss 2.765782, accuracy 0.348958\n",
      "epoch 100, loss 2.172428, accuracy 0.481771\n",
      "epoch 150, loss 1.941215, accuracy 0.544271\n",
      "epoch 200, loss 1.565606, accuracy 0.614583\n",
      "epoch 250, loss 1.502710, accuracy 0.635417\n",
      "epoch 300, loss 1.380162, accuracy 0.656250\n",
      "epoch 350, loss 1.274877, accuracy 0.687500\n",
      "epoch 400, loss 1.421969, accuracy 0.645833\n",
      "epoch 450, loss 1.108888, accuracy 0.723958\n",
      "epoch 500, loss 1.148727, accuracy 0.714844\n",
      "epoch 550, loss 1.031485, accuracy 0.734375\n",
      "epoch 600, loss 1.256077, accuracy 0.673177\n",
      "epoch 650, loss 1.101010, accuracy 0.717448\n",
      "epoch 700, loss 1.027899, accuracy 0.726562\n",
      "epoch 750, loss 1.188729, accuracy 0.670573\n",
      "epoch 800, loss 0.728075, accuracy 0.812500\n",
      "epoch 850, loss 0.912237, accuracy 0.753906\n",
      "epoch 900, loss 0.806098, accuracy 0.779948\n",
      "epoch 950, loss 0.909736, accuracy 0.760417\n",
      "epoch 1000, loss 0.875729, accuracy 0.766927\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    batch_x = np.zeros((batch_size, sequence_length, dimension))\n",
    "    batch_y = np.zeros((batch_size, sequence_length, dimension))\n",
    "    batch_id = random.sample(possible_batch_id, batch_size)\n",
    "    prev_s = np.zeros((batch_size, size_layer))\n",
    "    for n in range(sequence_length):\n",
    "        id1 = [k + n for k in batch_id]\n",
    "        id2 = [k + n + 1 for k in batch_id]\n",
    "        batch_x[:,n,:] = onehot[id1, :]\n",
    "        batch_y[:,n,:] = onehot[id2, :]\n",
    "    layers = []\n",
    "    out_logits = np.zeros((batch_size, sequence_length, dimension))\n",
    "    for n in range(sequence_length):\n",
    "        layers.append(forward_recurrent(batch_x[:,n,:], prev_s, U - momentum * U_velocity, \n",
    "                                        W - momentum * W_velocity, V - momentum * V_velocity))\n",
    "        prev_s = layers[-1][3]\n",
    "        out_logits[:, n, :] = layers[-1][-1]\n",
    "    probs = softmax(out_logits.reshape((-1, dimension)))\n",
    "    y = np.argmax(batch_y.reshape((-1, dimension)),axis=1)\n",
    "    accuracy = np.mean(np.argmax(probs,axis=1) == y)\n",
    "    loss = cross_entropy(probs, batch_y.reshape((-1, dimension)))\n",
    "    delta = probs\n",
    "    delta[range(y.shape[0]), y] -= 1\n",
    "    delta = delta.reshape((batch_size, sequence_length, dimension))\n",
    "    dU = np.zeros(U.shape)\n",
    "    dV = np.zeros(V.shape)\n",
    "    dW = np.zeros(W.shape)\n",
    "    prev_state = np.zeros((batch_size, size_layer))\n",
    "    for n in range(sequence_length):\n",
    "        d_mul_v = delta[:, n, :]\n",
    "        dprev_s, dU_t, dW_t, dV_t = backward_recurrent(batch_x[:,n,:], prev_state, U, W, V, d_mul_v, layers[n])\n",
    "        prev_state = layers[n][3]\n",
    "        dV += dV_t\n",
    "        dU += dU_t\n",
    "        dW += dW_t\n",
    "    U_velocity = U_velocity * momentum + learning_rate * dU\n",
    "    U -= U_velocity\n",
    "    V_velocity = V_velocity * momentum + learning_rate * dV\n",
    "    V -= V_velocity\n",
    "    W_velocity = W_velocity * momentum + learning_rate * dW\n",
    "    W -= W_velocity\n",
    "    if (i+1) % 50 == 0:\n",
    "        print('epoch %d, loss %f, accuracy %f'%(i+1, loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
